{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:07:51.439111Z",
     "start_time": "2020-05-27T17:07:49.167552Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                     ClusterCentroids,\n",
    "                                     TomekLinks,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to track params & scoring\n",
    "cols = [\"Model\", \"Method\", \"cv_score\", \"training_score\", \"accuracy\", \"precision\", \"recall\", \"f1-score\", \"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "model_tracker = pd.DataFrame(columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:07:51.800163Z",
     "start_time": "2020-05-27T17:07:51.667254Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-46de3ca201eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating class called tiny target which will evaluate several different sampling techniques on a user selected model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mtiny_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMaxAbsScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-46de3ca201eb>\u001b[0m in \u001b[0;36mtiny_target\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating class called tiny target which will evaluate several different sampling techniques on a user selected model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mtiny_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMaxAbsScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# creating class called tiny target which will evaluate several different sampling techniques on a user selected model\n",
    "class tiny_target:\n",
    "    def __init__(self, X, y, scaler= MaxAbsScaler(), model= LogisticRegression(), sampling_strategy= 0.5, train_size = 0.3, run_all = True, cv_scoring = \"recall\", stratify = y, cv= 5, tracker = None, name = \"model\"):\n",
    "        if tracker is not None:\n",
    "            self.tracker = tracker\n",
    "        else:\n",
    "            cols = [\"Model\", \"Method\", \"cv_score\", \"training_score\", \"accuracy\", \"precision\", \"recall\", \"f1-score\", \"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "            model_tracker = pd.DataFrame(columns= cols)\n",
    "            self.tracker = model_tracker\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.model = model\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.train_size = train_size\n",
    "        self.stratify = stratify\n",
    "        self.cv = cv\n",
    "        self.name = name\n",
    "        self.cv_scoring = cv_scoring\n",
    "        self.tracker = tracker\n",
    "    \n",
    "    def model_runner(self):\n",
    "        \"\"\"runs models and appends various scoring metrics (y target focused) to model tracker\"\"\"\n",
    "        self.model.fit(self.X_train_new, self.y_train_new)\n",
    "        self.scores = cross_val_score(self.model, self.X_train_new, self.y_train_new, cv= self.cv, scoring = self.cv_scoring)\n",
    "        self.training_score = self.model.score(self.X_train_new, self.y_train_new)\n",
    "\n",
    "        # predict and get classification report & confusion matrix info\n",
    "        self.predictions = self.model.predict(self.X_test)\n",
    "        self.class_report = classification_report(self.y_test, self.predictions, output_dict= True)\n",
    "        self.tn, self.fp, self.fn, self.tp = confusion_matrix(self.y_test, self.predictions).ravel()\n",
    "        \n",
    "        self.model_tracker()\n",
    "        \n",
    "    def model_tracker(self):\n",
    "        self.results = pd.DataFrame({'Model': self.name, 'Method': self.method, 'cv_score': self.scores.mean(), \n",
    "                                'training_score': self.training_score,'accuracy': self.class_report[\"accuracy\"],\n",
    "                                'precision': self.class_report[\"1.0\"][\"precision\"], 'recall': self.class_report[\"1.0\"][\"recall\"],\n",
    "                                'f1-score': self.class_report[\"1.0\"][\"f1-score\"], 'TP': self.tp, 'FP': self.fp,\n",
    "                                'TN': self.tn, 'FN': self.fn}, index=[len(model_tracker.index)])\n",
    "        self.tracker =  pd.concat([self.tracker, self.results])\n",
    "    \n",
    "    def run_all(self):\n",
    "        self.random_under()\n",
    "        self.clustercentroids()\n",
    "        self.tomeklinks()\n",
    "        self.neighbourhoodclean()\n",
    "        self.nearmiss()\n",
    "        self.smote_upsample()\n",
    "        self.random_over()\n",
    "        self.adasyn()\n",
    "        return self.tracker\n",
    "    \n",
    "    def random_under(self):\n",
    "        \"\"\"Randomly undersamples the predictor class. Can lead to loss of information \n",
    "        unless the majority class is relatively uniform\"\"\"\n",
    "        \n",
    "        self.sampler = RandomUnderSampler(sampling_strategy= self.sampling_strategy, random_state= 13)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split( \\\n",
    "            self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.method = \"Random Under\"\n",
    "        self.model_runner() \n",
    "        print(\"Random undersample run complete\")\n",
    "        return self.tracker\n",
    "    \n",
    "    def clustercentroids(self):\n",
    "        \"\"\"This method undersamples the majority class by replacing a cluster of majority samples. \n",
    "        Clusters of majority class found with K-mean algorithms. Then it keeps the cluster centroids of the \n",
    "        N clusters as the new majority samples\"\"\"\n",
    "        self.sampler = ClusterCentroids(sampling_strategy= self.sampling_strategy, random_state= 13)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.method = \"Cluster Centroids\"\n",
    "        self.model_runner()\n",
    "        \n",
    "        print(\"Cluster centroids run complete\")\n",
    "        return self.tracker\n",
    "    \n",
    "    def tomeklinks(self):\n",
    "        \"\"\"Finds samples near the borderline of the two classess. Given two instances, a & b seperated by distance\n",
    "        d(a,b) the pair is called a Tomek link if there is no instance c such that d(a,c) < d(a,b) or d(b,c) < d(a,b)\n",
    "        Instances within Tomek links are considered noise or borderline and are thus removed\"\"\"\n",
    "        \n",
    "        self.sampler = TomekLinks()\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.method = \"Tomek Links\"\n",
    "        self.model_runner()\n",
    "        \n",
    "        print(\"TomekLinks run complete\")\n",
    "        return self.tracker\n",
    "    \n",
    "    def neighbourhoodclean(self):\n",
    "        \"\"\" Edited Nearest Neighbor Rule (ENN) to remove any instance whose class label is different from the class\n",
    "        of at least two of its three nearest neighbors. Neighbourhood cleaning rule uses ENN to remove majority samples\n",
    "        Finds three nearest neighbors for each training set instance, if majority class and opposite to its neighbours \n",
    "        it is removed. If belongs to the target class than the neighbours are removed\"\"\"\n",
    "        \n",
    "        self.sampler = NeighbourhoodCleaningRule()\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.method = \"Neighbourhood Clean\"\n",
    "        self.model_runner()\n",
    "        \n",
    "        print(\"Neighbourhood Cleaning run complete\")\n",
    "        return self.tracker\n",
    "    \n",
    "    def nearmiss(self):\n",
    "        \"\"\"Calculates distances between all instance of majority and minority classes. K instances of the majority\n",
    "        class with smallest distances to minority are selected and removed\"\"\"\n",
    "        \n",
    "        self.sampler = NearMiss(sampling_strategy= self.sampling_strategy)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.method = \"Near Miss\"\n",
    "        self.model_runner()\n",
    "       \n",
    "        print(\"Near Miss run complete\")\n",
    "        return self.tracker\n",
    "        \n",
    "    \n",
    "    def smote_upsample(self, k_neighbors = 5):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.sampler = SMOTE(sampling_strategy= self.sampling_strategy, random_state= 13, k_neighbors= self.k_neighbors)\n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "\n",
    "        cv = KFold(n_splits=5, shuffle = True)\n",
    "        self.scores = np.array([])\n",
    "        for train_fold_index, val_fold_index in cv.split(self.X_train, self.y_train):\n",
    "         \n",
    "             # Get the training data\n",
    "            X_train_fold, y_train_fold = self.X_train[train_fold_index], self.y_train[train_fold_index]\n",
    "        # Get the validation data\n",
    "            X_val_fold, y_val_fold = self.X_train[val_fold_index], self.y_train[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "            X_train_fold_upsample, y_train_fold_upsample = self.sampler.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "            model_obj = self.model.fit(X_train_fold_upsample, y_train_fold_upsample)\n",
    "            score = recall_score(y_val_fold, model_obj.predict(X_val_fold))\n",
    "            self.scores = np.append(self.scores, score)  \n",
    "        \n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.model.fit(self.X_train_new, self.y_train_new)\n",
    "        self.training_score = self.model.score(self.X_train_new, self.y_train_new)\n",
    "\n",
    "        # predict and get classification report & confusion matrix info\n",
    "        self.predictions = self.model.predict(self.X_test)\n",
    "        self.class_report = classification_report(self.y_test, self.predictions, output_dict= True)\n",
    "        self.tn, self.fp, self.fn, self.tp = confusion_matrix(self.y_test, self.predictions).ravel()\n",
    "        self.method = \"SMOTE\"\n",
    "        self.model_tracker()\n",
    "        \n",
    "        print(\"SMOTE run complete\")\n",
    "        return self.tracker\n",
    "    \n",
    "    def random_over(self):\n",
    "        self.sampler = RandomOverSampler(sampling_strategy= self.sampling_strategy, random_state= 13)\n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "\n",
    "        cv = KFold(n_splits=5, shuffle = True)\n",
    "        self.scores = np.array([])\n",
    "        for train_fold_index, val_fold_index in cv.split(self.X_train, self.y_train):\n",
    "         \n",
    "             # Get the training data\n",
    "            X_train_fold, y_train_fold = self.X_train[train_fold_index], self.y_train[train_fold_index]\n",
    "        # Get the validation data\n",
    "            X_val_fold, y_val_fold = self.X_train[val_fold_index], self.y_train[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "            X_train_fold_upsample, y_train_fold_upsample = self.sampler.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "            model_obj = self.model.fit(X_train_fold_upsample, y_train_fold_upsample)\n",
    "            score = recall_score(y_val_fold, model_obj.predict(X_val_fold))\n",
    "            self.scores = np.append(self.scores, score)  \n",
    "        \n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.model.fit(self.X_train_new, self.y_train_new)\n",
    "        self.training_score = self.model.score(self.X_train_new, self.y_train_new)\n",
    "      \n",
    "\n",
    "        # predict and get classification report & confusion matrix info\n",
    "        self.predictions = self.model.predict(self.X_test)\n",
    "        self.class_report = classification_report(self.y_test, self.predictions, output_dict= True)\n",
    "        self.tn, self.fp, self.fn, self.tp = confusion_matrix(self.y_test, self.predictions).ravel()\n",
    "        self.method = \"Random oversample\"\n",
    "        self.model_tracker()\n",
    "        \n",
    "        print(\"Random oversample run complete\")\n",
    "        return self.tracker\n",
    "        \n",
    "\n",
    "        \n",
    "    def adasyn(self, n_neighbors = 5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.sampler = ADASYN(sampling_strategy= self.sampling_strategy, random_state= 13, n_neighbors= self.n_neighbors)\n",
    "        self.X_train, self.X_test, self.y_train , self.y_test = train_test_split(self.X, self.y, train_size=self.train_size, stratify=self.stratify, random_state=13)\n",
    "\n",
    "        cv = KFold(n_splits=5, shuffle = True)\n",
    "        self.scores = np.array([])\n",
    "        for train_fold_index, val_fold_index in cv.split(self.X_train, self.y_train):\n",
    "         \n",
    "             # Get the training data\n",
    "            X_train_fold, y_train_fold = self.X_train[train_fold_index], self.y_train[train_fold_index]\n",
    "        # Get the validation data\n",
    "            X_val_fold, y_val_fold = self.X_train[val_fold_index], self.y_train[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "            X_train_fold_upsample, y_train_fold_upsample = self.sampler.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "            model_obj = self.model.fit(X_train_fold_upsample, y_train_fold_upsample)\n",
    "            score = recall_score(y_val_fold, model_obj.predict(X_val_fold))\n",
    "            self.scores = np.append(self.scores, score)  \n",
    "        \n",
    "        self.X_train_new, self.y_train_new = self.sampler.fit_resample(self.X_train, self.y_train)\n",
    "        self.model.fit(self.X_train_new, self.y_train_new)\n",
    "        self.training_score = self.model.score(self.X_train_new, self.y_train_new)\n",
    "\n",
    "        # predict and get classification report & confusion matrix info\n",
    "        self.predictions = self.model.predict(self.X_test)\n",
    "        self.class_report = classification_report(self.y_test, self.predictions, output_dict= True)\n",
    "        self.tn, self.fp, self.fn, self.tp = confusion_matrix(self.y_test, self.predictions).ravel()\n",
    "        self.method = \"ADASYN\"\n",
    "        self.model_tracker()\n",
    "        \n",
    "        print(\"ADASYN run complete\")\n",
    "        return self.tracker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
